---
title: 踩过的那些坑
typora-root-url: ../../source
date: 2021-06-16 10:44:32
tags:
categories:
sticky:
---

### spark

#### spark-submit提交任务cores为0

![image-20210616104545792](/images/%E8%B8%A9%E8%BF%87%E7%9A%84%E9%82%A3%E4%BA%9B%E5%9D%91/image-20210616104545792.png)

解决：设置executor memory, 默认为8g

![image-20210616104650872](/images/%E8%B8%A9%E8%BF%87%E7%9A%84%E9%82%A3%E4%BA%9B%E5%9D%91/image-20210616104650872.png)

### Linux

#### crontab任务不生效，单独运行sh文件生效

解决：sh脚本中绝对路径改为完整路径

![image-20210616105616403](/images/%E8%B8%A9%E8%BF%87%E7%9A%84%E9%82%A3%E4%BA%9B%E5%9D%91/image-20210616105616403.png)

#### crontab任务按小时执行不生效

```shell
* * * * * /bin/bash /home/galaxy/volumes/cyber_narrator/arangodb/execute-load-relationship.sh  # 每分钟执行一次，生效

0 * * * * /bin/bash /home/galaxy/volumes/cyber_narrator/arangodb/execute-load-relationship.sh  # 每小时0分执行一次，不生效
```

解决：

反复排错之后发现既不是脚本的问题（按分钟可以生效），也不是配置的问题。查看crontab运行命令：

```shell
[root@galaxy-cn-55 arangodb]# crontab -l
0 */1 * * * /home/bigdata/spark-2.2.3-bin-hadoop2.7/execute-spark-task.sh
0 * * * * /bin/bash /home/galaxy/volumes/cyber_narrator/arangodb/execute-load-relationship.sh
```

同样的执行条件有一个任务

`0 */1 * * * /home/bigdata/spark-2.2.3-bin-hadoop2.7/execute-spark-task.sh`

这个脚本中运行的时候，把spark-submit任务都kill了

```shell
source /etc/profile

pid=`ps -ef | grep SparkSubmit | grep -v grep | awk '{print $2}'`
kill -9 $pid

……
```

重新配置运行时间，错开执行：

```
30 * * * * /bin/bash /home/galaxy/volumes/cyber_narrator/arangodb/execute-load-relationship.sh
```

