---
title: 深度学习推荐系统实战
typora-root-url: ../../source
date: 2021-03-08 10:14:42
tags:
catagories: 
- 推荐
- 笔记
sticky:
---

[toc]

# 基础架构篇

### 1-1 深度学习推荐系统的经典技术架构长啥样？

#### 1. 推荐系统解决的根本问题是什么

在“信息过载”的情况下，用户如何高效获取感兴趣的信息：

对于某个用户U（User），在特定场景C（Context）下，针对海量的“物品”信息构建一个函数 ，预测用户对特定候选物品I（Item）的喜好程度，再根据喜好程度对所有候选物品进行排序，生成推荐列表的问题。

#### 2. 深度学习推荐系统的技术架构

需要解决的问题有两类：数据部分、模型部分

<img src="/images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98-%EF%BC%9A%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E7%AF%87/a87530cf45fb76480bf5b60b9feb60c1.jpg" alt="a87530cf45fb76480bf5b60b9feb60c1" style="zoom: 40%;" />

### 1-2 Sparrow RecSys

功能：首页、详情页、推荐页

数据来源：movilens的1000部电影，包括基本信息、打分、外部链接

架构图：

<img src="/images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98-%EF%BC%9A%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E7%AF%87/8cee6a7eeebda9745bfbe1b6yy18c59e.jpg" alt="8cee6a7eeebda9745bfbe1b6yy18c59e" style="zoom:30%;" />

# 特征工程篇

### 2-1 原则

- 尽可能地让特征工程抽取出的一组特征，能够保留推荐环境及用户行为过程中的所有“有用“信息，并且尽量摒弃冗余信息。
- 在已有的、可获得的数据基础上，“尽量”保留有用信息是现实中构建特征工程的原则。

常用特征：用户行为数据；用户关系数据；属性、标签类数据；内容类数据；场景信息（上下文信息）

### 2-2 Spark特征处理

#### 概念

Spark 是一个分布式计算平台。所谓分布式，指的是计算节点之间不共享内存，需要通过网络通信的方式交换数据。Spark 最典型的应用方式就是建立在大量廉价的计算节点上，这些节点可以是廉价主机，也可以是虚拟的 Docker Container（Docker 容器）。

#### 工作方式

<img src="/images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98-%EF%BC%9A%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E7%AF%87/4ae1153e4daee39985c357ed796eca9b.jpeg" alt="4ae1153e4daee39985c357ed796eca9b" style="zoom:50%;" />

在 Spark 平台上处理任务的时候，会将这个任务拆解成一个子任务 DAG（Directed Acyclic Graph，有向无环图），再根据 DAG 决定程序各步骤执行的方法。

<img src="/images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98-%EF%BC%9A%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E7%AF%87/01524cdf0ff7f64bcf86c656dd5470fd.jpeg" alt="01524cdf0ff7f64bcf86c656dd5470fd" style="zoom:50%;" />

最关键的过程是我们要理解哪些是可以纯并行处理的部分，哪些是必须 shuffle（混洗）和 reduce 的部分。

shuffle 指的是所有 partition 的数据必须进行洗牌后才能得到下一步的数据，最典型的操作就是图 2 中的 groupByKey 操作和 join 操作。以 join 操作为例，我们必须对 textFile 数据和 hadoopFile 数据做全量的匹配才可以得到 join 后的 dataframe（Spark 保存数据的结构）。而 groupByKey 操作则需要对数据中所有相同的 key 进行合并，也需要全局的 shuffle 才能完成。与之相比，map、filter 等操作仅需要逐条地进行数据处理和转换，不需要进行数据间的操作，因此各 partition 之间可以完全并行处理。shuffle 操作需要在不同计算节点之间进行数据交换，非常消耗计算、通信及存储资源，因此 shuffle 操作是 spark 程序应该尽量避免的。

<img src="/images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/6e50b4010c27fac81acb0b230516e113-20210316160135239.jpeg" alt="6e50b4010c27fac81acb0b230516e113" style="zoom:50%;" />

​															<font color = "grey">图3 被shuffle操作分割的DAG stages</font>

Stage 内部数据高效并行计算，Stage 边界处进行消耗资源的 shuffle 操作或者最终的 reduce 操作。



